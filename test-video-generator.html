<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Test Video Generator</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }

        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }

        .section {
            margin: 30px 0;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        .section h2 {
            color: #555;
            margin-top: 0;
        }

        .controls {
            display: flex;
            gap: 15px;
            margin: 15px 0;
            flex-wrap: wrap;
        }

        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }

        label {
            font-weight: 600;
            color: #666;
        }

        input, select, button {
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 14px;
        }

        button {
            background: #007bff;
            color: white;
            border: none;
            cursor: pointer;
            font-weight: 600;
        }

        button:hover {
            background: #0056b3;
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            display: none;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }

        video {
            width: 100%;
            max-width: 600px;
            margin: 20px 0;
            border-radius: 8px;
        }

        .test-videos {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .test-video-card {
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 15px;
            background: #f9f9f9;
        }

        .test-video-card h3 {
            margin-top: 0;
            color: #333;
        }

        .download-btn {
            background: #28a745;
            margin-top: 10px;
            width: 100%;
        }

        .download-btn:hover {
            background: #1e7e34;
        }

        .audio-visualization {
            width: 100%;
            height: 100px;
            background: #000;
            border-radius: 5px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽµ Audio Test Video Generator</h1>
        <p style="text-align: center; color: #666;">Generate test videos with various audio characteristics for video clipper validation</p>

        <div class="section">
            <h2>Custom Test Video Generator</h2>
            <div class="controls">
                <div class="control-group">
                    <label>Duration (seconds)</label>
                    <input type="number" id="duration" value="30" min="5" max="300">
                </div>
                <div class="control-group">
                    <label>Audio Type</label>
                    <select id="audioType">
                        <option value="tone">Pure Tone</option>
                        <option value="sweep">Frequency Sweep</option>
                        <option value="speech">Synthetic Speech</option>
                        <option value="music">Musical Sequence</option>
                        <option value="mixed">Mixed Content</option>
                        <option value="silence">Silence</option>
                    </select>
                </div>
                <div class="control-group">
                    <label>Frequency (Hz)</label>
                    <input type="number" id="frequency" value="440" min="20" max="20000">
                </div>
                <div class="control-group">
                    <label>Sample Rate</label>
                    <select id="sampleRate">
                        <option value="44100">44.1 kHz</option>
                        <option value="48000">48 kHz</option>
                        <option value="96000">96 kHz</option>
                    </select>
                </div>
                <div class="control-group">
                    <label>Channels</label>
                    <select id="channels">
                        <option value="1">Mono</option>
                        <option value="2">Stereo</option>
                    </select>
                </div>
            </div>
            <button id="generateCustom">Generate Custom Test Video</button>
            <div class="status" id="customStatus"></div>
            <video id="customPreview" controls style="display: none;"></video>
        </div>

        <div class="section">
            <h2>Pre-defined Test Videos</h2>
            <p>Generate a complete set of test videos for comprehensive audio validation:</p>
            <button id="generateAll">Generate All Test Videos</button>
            <div class="status" id="allStatus"></div>

            <div class="test-videos" id="testVideos">
                <!-- Generated test videos will appear here -->
            </div>
        </div>

        <div class="section">
            <h2>Audio Analysis Tools</h2>
            <div class="controls">
                <input type="file" id="fileInput" accept="video/*" style="display: none;">
                <button onclick="document.getElementById('fileInput').click()">Load Video for Analysis</button>
                <button id="analyzeAudio" disabled>Analyze Audio</button>
            </div>
            <div class="status" id="analysisStatus"></div>
            <canvas class="audio-visualization" id="audioVisualization"></canvas>
            <div id="analysisResults" style="margin-top: 20px;"></div>
        </div>
    </div>

    <script>
        class AudioTestVideoGenerator {
            constructor() {
                this.audioContext = null;
                this.currentVideo = null;
                this.testVideos = [];

                this.initializeElements();
                this.setupEventListeners();
                this.initializeAudioContext();
            }

            initializeElements() {
                this.generateCustomBtn = document.getElementById('generateCustom');
                this.generateAllBtn = document.getElementById('generateAll');
                this.analyzeAudioBtn = document.getElementById('analyzeAudio');
                this.fileInput = document.getElementById('fileInput');
                this.customPreview = document.getElementById('customPreview');
                this.audioVisualization = document.getElementById('audioVisualization');
                this.testVideosContainer = document.getElementById('testVideos');
            }

            setupEventListeners() {
                this.generateCustomBtn.addEventListener('click', () => this.generateCustomVideo());
                this.generateAllBtn.addEventListener('click', () => this.generateAllTestVideos());
                this.analyzeAudioBtn.addEventListener('click', () => this.analyzeAudio());
                this.fileInput.addEventListener('change', (e) => this.loadVideoForAnalysis(e.target.files[0]));
            }

            async initializeAudioContext() {
                try {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Audio context initialized');
                } catch (error) {
                    this.showStatus('error', 'customStatus', 'Audio context not supported in this browser');
                    console.error('Failed to initialize audio context:', error);
                }
            }

            async generateCustomVideo() {
                const duration = parseInt(document.getElementById('duration').value);
                const audioType = document.getElementById('audioType').value;
                const frequency = parseInt(document.getElementById('frequency').value);
                const sampleRate = parseInt(document.getElementById('sampleRate').value);
                const channels = parseInt(document.getElementById('channels').value);

                this.showStatus('info', 'customStatus', 'Generating custom test video...');

                try {
                    const videoBlob = await this.createTestVideo({
                        duration,
                        audioType,
                        frequency,
                        sampleRate,
                        channels,
                        title: `Custom ${audioType} ${frequency}Hz ${channels}ch`
                    });

                    this.customPreview.src = URL.createObjectURL(videoBlob);
                    this.customPreview.style.display = 'block';

                    this.showStatus('success', 'customStatus', 'Custom test video generated successfully!');
                } catch (error) {
                    this.showStatus('error', 'customStatus', `Failed to generate video: ${error.message}`);
                }
            }

            async generateAllTestVideos() {
                this.showStatus('info', 'allStatus', 'Generating complete test video suite...');
                this.generateAllBtn.disabled = true;

                const testConfigs = [
                    // Audio quality tests
                    { duration: 30, audioType: 'tone', frequency: 440, sampleRate: 44100, channels: 1, title: 'Mono 440Hz (44.1kHz)' },
                    { duration: 30, audioType: 'tone', frequency: 440, sampleRate: 48000, channels: 2, title: 'Stereo 440Hz (48kHz)' },
                    { duration: 30, audioType: 'tone', frequency: 1000, sampleRate: 96000, channels: 2, title: 'High-res 1kHz (96kHz)' },

                    // Frequency response tests
                    { duration: 30, audioType: 'sweep', frequency: 20, sampleRate: 48000, channels: 2, title: 'Frequency Sweep (20Hz-20kHz)' },
                    { duration: 15, audioType: 'tone', frequency: 100, sampleRate: 44100, channels: 2, title: 'Low Frequency (100Hz)' },
                    { duration: 15, audioType: 'tone', frequency: 10000, sampleRate: 48000, channels: 2, title: 'High Frequency (10kHz)' },

                    // Content type tests
                    { duration: 45, audioType: 'speech', frequency: 440, sampleRate: 44100, channels: 1, title: 'Synthetic Speech (Mono)' },
                    { duration: 60, audioType: 'music', frequency: 440, sampleRate: 48000, channels: 2, title: 'Musical Sequence' },
                    { duration: 30, audioType: 'mixed', frequency: 440, sampleRate: 44100, channels: 2, title: 'Mixed Content' },

                    // Edge cases
                    { duration: 20, audioType: 'silence', frequency: 0, sampleRate: 44100, channels: 2, title: 'Silent Video' },
                    { duration: 120, audioType: 'tone', frequency: 440, sampleRate: 44100, channels: 2, title: 'Long Duration (2min)' },
                    { duration: 5, audioType: 'tone', frequency: 440, sampleRate: 48000, channels: 2, title: 'Short Duration (5s)' }
                ];

                this.testVideosContainer.innerHTML = '';
                this.testVideos = [];

                for (let i = 0; i < testConfigs.length; i++) {
                    const config = testConfigs[i];
                    try {
                        this.showStatus('info', 'allStatus', `Generating ${config.title} (${i + 1}/${testConfigs.length})...`);

                        const videoBlob = await this.createTestVideo(config);
                        this.testVideos.push({ blob: videoBlob, config });

                        this.addTestVideoCard(videoBlob, config);

                        // Small delay to prevent browser from being overwhelmed
                        await new Promise(resolve => setTimeout(resolve, 100));
                    } catch (error) {
                        console.error(`Failed to generate ${config.title}:`, error);
                    }
                }

                this.generateAllBtn.disabled = false;
                this.showStatus('success', 'allStatus', `Generated ${this.testVideos.length} test videos successfully!`);
            }

            async createTestVideo(config) {
                const { duration, audioType, frequency, sampleRate, channels, title } = config;

                // Create canvas for video
                const canvas = document.createElement('canvas');
                canvas.width = 640;
                canvas.height = 480;
                const ctx = canvas.getContext('2d');

                // Create audio buffer
                const audioBuffer = await this.generateAudioBuffer(audioType, duration, frequency, sampleRate, channels);

                // Set up recording
                const canvasStream = canvas.captureStream(30);
                const audioStream = this.createAudioStreamFromBuffer(audioBuffer, sampleRate);

                const combinedStream = new MediaStream();
                canvasStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
                audioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));

                const recorder = new MediaRecorder(combinedStream, {
                    mimeType: 'video/webm; codecs="vp8, opus"',
                    audioBitsPerSecond: 128000,
                    videoBitsPerSecond: 1000000
                });

                const chunks = [];
                recorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        chunks.push(event.data);
                    }
                };

                return new Promise((resolve, reject) => {
                    recorder.onstop = () => {
                        const blob = new Blob(chunks, { type: 'video/webm' });
                        resolve(blob);
                    };

                    recorder.onerror = reject;

                    // Start recording
                    recorder.start();

                    // Draw video frames
                    const startTime = Date.now();
                    const drawFrame = () => {
                        const elapsed = (Date.now() - startTime) / 1000;

                        // Clear canvas
                        ctx.fillStyle = '#1a1a1a';
                        ctx.fillRect(0, 0, canvas.width, canvas.height);

                        // Draw test pattern
                        ctx.fillStyle = '#00ff00';
                        ctx.font = '24px Arial';
                        ctx.textAlign = 'center';
                        ctx.fillText(title, canvas.width / 2, 50);

                        ctx.font = '18px Arial';
                        ctx.fillText(`Time: ${elapsed.toFixed(1)}s / ${duration}s`, canvas.width / 2, 100);
                        ctx.fillText(`Frequency: ${frequency}Hz`, canvas.width / 2, 130);
                        ctx.fillText(`Sample Rate: ${sampleRate}Hz`, canvas.width / 2, 160);
                        ctx.fillText(`Channels: ${channels}`, canvas.width / 2, 190);

                        // Draw audio visualization
                        this.drawAudioVisualization(ctx, audioType, elapsed, frequency);

                        if (elapsed < duration) {
                            requestAnimationFrame(drawFrame);
                        } else {
                            recorder.stop();
                        }
                    };

                    drawFrame();
                });
            }

            async generateAudioBuffer(audioType, duration, frequency, sampleRate, channels) {
                const length = sampleRate * duration;
                const audioBuffer = this.audioContext.createBuffer(channels, length, sampleRate);

                for (let channel = 0; channel < channels; channel++) {
                    const data = audioBuffer.getChannelData(channel);

                    switch (audioType) {
                        case 'tone':
                            this.generateTone(data, frequency, sampleRate, channel === 1 ? 1.5 : 1.0);
                            break;
                        case 'sweep':
                            this.generateSweep(data, 20, 20000, sampleRate);
                            break;
                        case 'speech':
                            this.generateSpeech(data, sampleRate);
                            break;
                        case 'music':
                            this.generateMusic(data, sampleRate);
                            break;
                        case 'mixed':
                            this.generateMixed(data, sampleRate);
                            break;
                        case 'silence':
                            // Data is already zeroed
                            break;
                    }
                }

                return audioBuffer;
            }

            generateTone(data, frequency, sampleRate, phaseOffset = 1.0) {
                for (let i = 0; i < data.length; i++) {
                    data[i] = Math.sin(2 * Math.PI * frequency * i / sampleRate * phaseOffset) * 0.3;
                }
            }

            generateSweep(data, startFreq, endFreq, sampleRate) {
                const freqRange = endFreq - startFreq;
                for (let i = 0; i < data.length; i++) {
                    const progress = i / data.length;
                    const freq = startFreq + (freqRange * progress);
                    data[i] = Math.sin(2 * Math.PI * freq * i / sampleRate) * 0.3;
                }
            }

            generateSpeech(data, sampleRate) {
                // Simple speech-like formant synthesis
                for (let i = 0; i < data.length; i++) {
                    const t = i / sampleRate;
                    const f0 = 120; // Fundamental frequency
                    const formant1 = Math.sin(2 * Math.PI * 800 * t) * 0.3;
                    const formant2 = Math.sin(2 * Math.PI * 1200 * t) * 0.2;
                    const fundamental = Math.sin(2 * Math.PI * f0 * t) * 0.1;

                    // Add modulation to simulate speech patterns
                    const modulation = 0.5 + 0.5 * Math.sin(2 * Math.PI * 3 * t);
                    data[i] = (formant1 + formant2 + fundamental) * modulation * 0.3;
                }
            }

            generateMusic(data, sampleRate) {
                // Generate a simple chord progression
                const chords = [
                    [261.63, 329.63, 392.00], // C major
                    [293.66, 369.99, 440.00], // D minor
                    [329.63, 415.30, 493.88], // E minor
                    [349.23, 440.00, 523.25]  // F major
                ];

                for (let i = 0; i < data.length; i++) {
                    const t = i / sampleRate;
                    const chordIndex = Math.floor((t * 2) % chords.length);
                    const chord = chords[chordIndex];

                    let sample = 0;
                    chord.forEach(freq => {
                        sample += Math.sin(2 * Math.PI * freq * t) * 0.1;
                    });

                    data[i] = sample;
                }
            }

            generateMixed(data, sampleRate) {
                // Mix speech, tone, and music
                for (let i = 0; i < data.length; i++) {
                    const t = i / sampleRate;
                    const tone = Math.sin(2 * Math.PI * 440 * t) * 0.1;
                    const speech = Math.sin(2 * Math.PI * 800 * t) * Math.sin(2 * Math.PI * 3 * t) * 0.1;
                    const noise = (Math.random() - 0.5) * 0.05;

                    data[i] = tone + speech + noise;
                }
            }

            createAudioStreamFromBuffer(audioBuffer, sampleRate) {
                const audioContext = new AudioContext({ sampleRate });
                const source = audioContext.createBufferSource();
                const destination = audioContext.createMediaStreamDestination();

                source.buffer = audioBuffer;
                source.connect(destination);
                source.start();

                return destination.stream;
            }

            drawAudioVisualization(ctx, audioType, elapsed, frequency) {
                const centerX = ctx.canvas.width / 2;
                const centerY = ctx.canvas.height / 2 + 50;
                const radius = 100;

                ctx.strokeStyle = '#00ff00';
                ctx.lineWidth = 2;
                ctx.beginPath();

                switch (audioType) {
                    case 'tone':
                        // Draw sine wave
                        for (let i = 0; i < 360; i++) {
                            const angle = (i + elapsed * frequency * 10) * Math.PI / 180;
                            const x = centerX + Math.cos(angle) * radius;
                            const y = centerY + Math.sin(angle) * 30;

                            if (i === 0) ctx.moveTo(x, y);
                            else ctx.lineTo(x, y);
                        }
                        break;
                    case 'sweep':
                        // Draw spiral
                        for (let i = 0; i < 360; i++) {
                            const angle = i * Math.PI / 180;
                            const currentRadius = radius * (0.2 + 0.8 * (elapsed % 5) / 5);
                            const x = centerX + Math.cos(angle) * currentRadius;
                            const y = centerY + Math.sin(angle) * currentRadius * 0.3;

                            if (i === 0) ctx.moveTo(x, y);
                            else ctx.lineTo(x, y);
                        }
                        break;
                    default:
                        // Draw circle
                        ctx.arc(centerX, centerY, radius * (0.5 + 0.5 * Math.sin(elapsed * 2)), 0, 2 * Math.PI);
                }

                ctx.stroke();
            }

            addTestVideoCard(videoBlob, config) {
                const card = document.createElement('div');
                card.className = 'test-video-card';

                const video = document.createElement('video');
                video.src = URL.createObjectURL(videoBlob);
                video.controls = true;
                video.style.width = '100%';

                const downloadBtn = document.createElement('button');
                downloadBtn.className = 'download-btn';
                downloadBtn.textContent = `Download ${config.title}`;
                downloadBtn.onclick = () => {
                    const a = document.createElement('a');
                    a.href = URL.createObjectURL(videoBlob);
                    a.download = `test-video-${config.title.replace(/[^a-z0-9]/gi, '-').toLowerCase()}.webm`;
                    a.click();
                };

                card.innerHTML = `
                    <h3>${config.title}</h3>
                    <p><strong>Duration:</strong> ${config.duration}s</p>
                    <p><strong>Audio:</strong> ${config.audioType} @ ${config.frequency}Hz</p>
                    <p><strong>Quality:</strong> ${config.sampleRate}Hz, ${config.channels} channel(s)</p>
                `;

                card.appendChild(video);
                card.appendChild(downloadBtn);

                this.testVideosContainer.appendChild(card);
            }

            loadVideoForAnalysis(file) {
                if (!file || !file.type.startsWith('video/')) {
                    this.showStatus('error', 'analysisStatus', 'Please select a valid video file');
                    return;
                }

                this.currentVideo = file;
                this.analyzeAudioBtn.disabled = false;
                this.showStatus('success', 'analysisStatus', `Loaded: ${file.name}`);
            }

            async analyzeAudio() {
                if (!this.currentVideo) return;

                this.showStatus('info', 'analysisStatus', 'Analyzing audio...');

                try {
                    const video = document.createElement('video');
                    video.src = URL.createObjectURL(this.currentVideo);

                    await new Promise((resolve, reject) => {
                        video.onloadedmetadata = resolve;
                        video.onerror = reject;
                    });

                    // Set up audio analysis
                    const audioContext = new AudioContext();
                    const source = audioContext.createMediaElementSource(video);
                    const analyser = audioContext.createAnalyser();

                    analyser.fftSize = 2048;
                    source.connect(analyser);

                    // Visualize audio
                    this.visualizeAudio(analyser);

                    // Generate analysis report
                    const analysis = {
                        duration: video.duration,
                        hasAudio: video.audioTracks ? video.audioTracks.length > 0 : 'Unknown',
                        sampleRate: audioContext.sampleRate,
                        fileSize: this.currentVideo.size,
                        type: this.currentVideo.type
                    };

                    this.displayAnalysisResults(analysis);
                    this.showStatus('success', 'analysisStatus', 'Audio analysis completed');

                } catch (error) {
                    this.showStatus('error', 'analysisStatus', `Analysis failed: ${error.message}`);
                }
            }

            visualizeAudio(analyser) {
                const canvas = this.audioVisualization;
                const ctx = canvas.getContext('2d');
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                const draw = () => {
                    analyser.getByteFrequencyData(dataArray);

                    ctx.fillStyle = '#000';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);

                    const barWidth = canvas.width / bufferLength;
                    let x = 0;

                    for (let i = 0; i < bufferLength; i++) {
                        const barHeight = (dataArray[i] / 255) * canvas.height;

                        ctx.fillStyle = `hsl(${i * 360 / bufferLength}, 50%, 50%)`;
                        ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

                        x += barWidth;
                    }

                    requestAnimationFrame(draw);
                };

                draw();
            }

            displayAnalysisResults(analysis) {
                const resultsDiv = document.getElementById('analysisResults');
                resultsDiv.innerHTML = `
                    <h3>Audio Analysis Results</h3>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px;">
                        <div><strong>Duration:</strong> ${analysis.duration?.toFixed(2) || 'Unknown'}s</div>
                        <div><strong>File Size:</strong> ${(analysis.fileSize / 1024 / 1024).toFixed(2)} MB</div>
                        <div><strong>File Type:</strong> ${analysis.type}</div>
                        <div><strong>Sample Rate:</strong> ${analysis.sampleRate} Hz</div>
                        <div><strong>Has Audio:</strong> ${analysis.hasAudio}</div>
                    </div>
                `;
            }

            showStatus(type, elementId, message) {
                const element = document.getElementById(elementId);
                element.textContent = message;
                element.className = `status ${type}`;
                element.style.display = 'block';

                if (type !== 'error') {
                    setTimeout(() => {
                        element.style.display = 'none';
                    }, 5000);
                }
            }
        }

        // Initialize the generator when the page loads
        window.addEventListener('load', () => {
            new AudioTestVideoGenerator();
        });
    </script>
</body>
</html>